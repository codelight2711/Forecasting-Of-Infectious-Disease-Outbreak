{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape weather data based on date and location\n",
    "\n",
    "The historical, international weather data on Weather Underground is keyed by airport abbreviation in the url. So, for each outbreak location, the closed airport is needed. To key these two sets of information, latitude and longitude are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:47:06.102791",
     "start_time": "2016-07-31T16:47:05.999204"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import dill\n",
    "from datetime import timedelta\n",
    "from csv_pkl_sql import save_it, pkl_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T05:32:58.431504",
     "start_time": "2016-07-25T05:32:54.941108"
    },
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Load airport and latitude/longitude data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:47:13.398091",
     "start_time": "2016-07-31T16:47:13.123886"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location   latitude  longitude\n",
       "0  Argentina-Buenos_Aires -34.603684 -58.381559"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_long_data = pd.read_pickle('../pkl/01_latitude_longitude_google.pkl')\n",
    "lat_long_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:47:39.997592",
     "start_time": "2016-07-31T16:47:39.824407"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>kind</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>max_runway</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BAHIA BLANCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BHI</td>\n",
       "      <td>SAZB</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-38.725</td>\n",
       "      <td>-62.169</td>\n",
       "      <td>8579.0</td>\n",
       "      <td>COMANDANTE ESPORA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  FAA IATA  ICAO    kind  latitude  longitude  max_runway  \\\n",
       "56  BAHIA BLANCA  NaN  BHI  SAZB  Medium   -38.725    -62.169      8579.0   \n",
       "\n",
       "                 name    country state  \n",
       "56  COMANDANTE ESPORA  Argentina   NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_info = pd.read_pickle('../pkl/02_airport_information_fallingrain.pkl')\n",
    "airport_info.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "The approximation for closest airport is crude, given that it doesn't convert latitude and longitude to distance but rather uses them directly. Given the relatively short distances involved, I think this is fine for a first pass of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:36:13.068256",
     "start_time": "2016-07-30T23:36:12.806037"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2062, 2) (1606, 1, 2) (1606, 2062) (1606,)\n"
     ]
    }
   ],
   "source": [
    "airport_coords = airport_info[['latitude', 'longitude']].values[np.newaxis, :]\n",
    "places_coords = np.rollaxis(lat_long_data[['latitude','longitude']].values[np.newaxis, :], 0, -1)\n",
    "\n",
    "dist_coords = ((places_coords - airport_coords)**2).sum(axis=-1)\n",
    "min_coords = dist_coords.argmin(axis=1)\n",
    "\n",
    "print airport_coords.shape, places_coords.shape, dist_coords.shape, min_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:36:18.229755",
     "start_time": "2016-07-30T23:36:18.191368"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 3)\n",
      "(1606, 9)\n"
     ]
    }
   ],
   "source": [
    "# Transfer the coordinates to the latitude/longitude data\n",
    "merge_data = lat_long_data.copy()\n",
    "\n",
    "print merge_data.shape\n",
    "\n",
    "merge_data['airport_index'] = airport_info.index[min_coords]\n",
    "\n",
    "# Now grap the airport and location info\n",
    "df = airport_info.loc[merge_data.airport_index, ['country','name','FAA','IATA','ICAO']]\n",
    "merge_data[['country','name','FAA','IATA','ICAO']] = df.set_index(merge_data.index)\n",
    "\n",
    "print merge_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:36:20.527261",
     "start_time": "2016-07-30T23:36:20.478129"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>airport_index</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "      <td>80</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "      <td>80</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina-Cordoba</td>\n",
       "      <td>-31.420083</td>\n",
       "      <td>-64.188776</td>\n",
       "      <td>149</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AMBROSIO L V TARAVELLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COR</td>\n",
       "      <td>SACO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina-Entre_Rios</td>\n",
       "      <td>-31.774665</td>\n",
       "      <td>-60.495646</td>\n",
       "      <td>398</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>GENERAL URQUIZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRA</td>\n",
       "      <td>SAAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina-Santa_Fe</td>\n",
       "      <td>-31.610658</td>\n",
       "      <td>-60.697294</td>\n",
       "      <td>527</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>SAUCE VIEJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SFN</td>\n",
       "      <td>SAAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location   latitude  longitude  airport_index    country  \\\n",
       "0  Argentina-Buenos_Aires -34.603684 -58.381559             80  Argentina   \n",
       "1          Argentina-CABA -34.603684 -58.381559             80  Argentina   \n",
       "2       Argentina-Cordoba -31.420083 -64.188776            149  Argentina   \n",
       "3    Argentina-Entre_Rios -31.774665 -60.495646            398  Argentina   \n",
       "4      Argentina-Santa_Fe -31.610658 -60.697294            527  Argentina   \n",
       "\n",
       "                       name  FAA IATA  ICAO  \n",
       "0  AEROPARQUE JORGE NEWBERY  NaN  AEP  SABE  \n",
       "1  AEROPARQUE JORGE NEWBERY  NaN  AEP  SABE  \n",
       "2    AMBROSIO L V TARAVELLA  NaN  COR  SACO  \n",
       "3           GENERAL URQUIZA  NaN  PRA  SAAP  \n",
       "4               SAUCE VIEJO  NaN  SFN  SAAV  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:36:25.077270",
     "start_time": "2016-07-30T23:36:24.983169"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "pkl_it(merge_data, '04_merged_latitude_longitude_airport_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Add infection dates\n",
    "Now combine with infection date data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:48:10.981855",
     "start_time": "2016-07-31T16:48:10.619391"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                location\n",
       "0 2016-03-19  Argentina-Buenos_Aires"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infection_data = pd.read_pickle('../pkl/03_infection_data_initial_import.pkl')\n",
    "infection_data = infection_data[['date','location']]\n",
    "infection_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:37:23.490344",
     "start_time": "2016-07-30T23:37:23.322888"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103630, 2) (1606, 9)\n",
      "(33405, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Catamarca</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTC</td>\n",
       "      <td>SANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Chaco</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RES</td>\n",
       "      <td>SARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Chubut</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL</td>\n",
       "      <td>SAVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                location    country  FAA IATA  ICAO\n",
       "0  2016-03-19  Argentina-Buenos_Aires  Argentina  NaN  AEP  SABE\n",
       "5  2016-03-19          Argentina-CABA  Argentina  NaN  AEP  SABE\n",
       "10 2016-03-19     Argentina-Catamarca  Argentina  NaN  CTC  SANC\n",
       "15 2016-03-19         Argentina-Chaco  Argentina  NaN  RES  SARE\n",
       "20 2016-03-19        Argentina-Chubut  Argentina  NaN  REL  SAVT"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print infection_data.shape, merge_data.shape\n",
    "\n",
    "merge_all = pd.merge(infection_data, \n",
    "                     merge_data[['location','country','FAA','IATA','ICAO']], \n",
    "                     on='location', \n",
    "                     how='left').drop_duplicates()\n",
    "\n",
    "print merge_all.shape\n",
    "\n",
    "merge_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Scrape data from Weather Underground\n",
    "\n",
    "Now scrape from weather underground. I want time shifted data, so need to get one and two weeks beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:38:49.584245",
     "start_time": "2016-07-30T23:38:49.526131"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "weather_scrape = (merge_all[['date','country','IATA','ICAO']]\n",
    "                  .drop_duplicates()\n",
    "                  .set_index(['country','IATA','ICAO'])\n",
    "                  )\n",
    "\n",
    "weather_scrape['date1'] = weather_scrape.date - timedelta(days=7)\n",
    "weather_scrape['date2'] = weather_scrape.date - timedelta(days=14)\n",
    "\n",
    "weather_scrape = (weather_scrape\n",
    "                  .stack()\n",
    "                  .reset_index(level=-1, drop=True)\n",
    "                  .reset_index()\n",
    "                  .rename(columns={0:'date'})\n",
    "                  .dropna(subset=['IATA','ICAO'], how='all')\n",
    "                 )\n",
    "\n",
    "weather_scrape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T23:40:27.764966",
     "start_time": "2016-07-30T23:40:27.735129"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def scrape_weekly_weather(date, df_row):\n",
    "    # Scrape the weekly data table\n",
    "    url_fmt = 'https://www.wunderground.com/history/airport/{}/{}/{}/{}/WeeklyHistory.html'\n",
    "    \n",
    "    try:\n",
    "        url = url_fmt.format(df_row.ICAO, date.year, \n",
    "                             date.month, date.day)\n",
    "    except:\n",
    "        url = url_fmt.format(df_row.IATA, date.year, \n",
    "                             date.month, date.day)\n",
    "    \n",
    "    try:\n",
    "        table = pd.read_html(url)[0].dropna(subset=['Max','Avg','Min','Sum'], how='all')\n",
    "        table.columns = ['Measurement','Max','Avg','Min','Sum']\n",
    "        table.set_index('Measurement', inplace=True)\n",
    "        table = table.stack()\n",
    "        time.sleep(1.0)\n",
    "    except:\n",
    "        table = pd.Series({'NULL':np.NaN}, index=pd.Index([0]))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-07-26T03:29:48.688Z"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Broke up into sections and did this on three different computers to speed it up\n",
    "# date_list is a divided up dataframe of weather_scrape\n",
    "\n",
    "for ndate, date in enumerate(date_list):\n",
    "    \n",
    "    print ndate\n",
    "    df_list = list()\n",
    "    \n",
    "    for num,(row,dat) in enumerate(airport_list.iterrows()):\n",
    "        \n",
    "        try:\n",
    "            df = scrape_weekly_weather(date, dat)\n",
    "        except:\n",
    "            df = pd.Series({'NULL':np.NaN}, index=pd.Index([row]))\n",
    "\n",
    "        df_list.append((date, dat.name, df))\n",
    "        \n",
    "    with open('../pkl/04_scrape_weekly_weather_data/df_list{}.pkl'.format(ndate),'w') as fh:\n",
    "        dill.dump(df_list, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T16:50:34.207252",
     "start_time": "2016-07-26T16:43:28.272093"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def clean_weather_data(entry):\n",
    "    index = pd.MultiIndex.from_tuples([(entry[0],\n",
    "                                        entry[1])]*len(entry[2]),\n",
    "                                      names=['date','index'])\n",
    "    \n",
    "    df = pd.DataFrame(entry[2].reset_index().values, \n",
    "                      index=index, \n",
    "                      columns=['measurement','type','value'])\n",
    "\n",
    "    mask = (df.measurement.isin(['Max Temperature','Mean Temperature',\n",
    "                                   'Min Temperature','Dew Point','Precipitation','Wind']))\n",
    "    df = df.loc[mask]\n",
    "    \n",
    "    mask = ((((df.measurement=='Precipitation')&(df.type=='Sum'))|(df.type=='Avg')) & \n",
    "            ((df.measurement=='Precipitation')&(df.type=='Avg')).pipe(np.invert))\n",
    "    df = df.loc[mask].drop(['type'], axis=1)\n",
    "    \n",
    "    df['value'] = (df.value\n",
    "                   .str.replace('-', '')\n",
    "                   .str.extract(r\"\"\"([0-9.-]+)\"\"\", expand=True)\n",
    "                   .astype(float)\n",
    "                   )\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_clean = list()\n",
    "\n",
    "\n",
    "for i in range(134):\n",
    "    with open('../pkl/04_scrape_weekly_weather_data/df_list{}.pkl'.format(i), 'r') as fh:\n",
    "        df_list = dill.load(fh)\n",
    "    \n",
    "    for df in enumerate(df_list):\n",
    "        if not df[1][2].isnull().all():\n",
    "            df_clean.append(clean_weather_data(df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:16:28.973089",
     "start_time": "2016-07-30T16:16:08.305452"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "weather_combined = pd.concat(df_clean, axis=0)\n",
    "weather_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:17:50.527878",
     "start_time": "2016-07-30T16:17:50.376452"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "weather_combined = pd.merge(weather_combined.reset_index(level=-1), \n",
    "                            airport_list, \n",
    "                            left_on='index', \n",
    "                            right_index=True).drop(['index'], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Shift historical weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:18:32.125243",
     "start_time": "2016-07-30T16:18:32.049709"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def time_shift(df, feature, week=1):\n",
    "    new_df = (pd.merge(df[['date', feature]].reset_index(),\n",
    "                       df[['date'+str(week), feature]].reset_index(),\n",
    "                       left_on=df.index.names + ['date'], \n",
    "                       right_on=df.index.names + ['date'+str(week)],\n",
    "                       suffixes=('',str(week)), \n",
    "                       how='inner')\n",
    "              .drop(['date'+str(week)] + df.index.names, axis=1)\n",
    "              .reset_index(level=-1, drop=True))\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "\n",
    "def create_weather_feature(df, feature):\n",
    "    df_new = (df.loc[df.measurement==feature]\n",
    "             .set_index(['ICAO','IATA','date','measurement'])\n",
    "             .unstack())\n",
    "    \n",
    "    df_new = df_new.reset_index(level=-1)\n",
    "    df_new.columns = ['date', feature]\n",
    "\n",
    "    df_new['date1'] = df_new.date + timedelta(days=7)\n",
    "    df_new['date2'] = df_new.date + timedelta(days=14)\n",
    "\n",
    "    df_new1 = (df_new\n",
    "            .groupby(level=[0,1])\n",
    "            .apply(lambda x: time_shift(x,feature, 1))\n",
    "            .reset_index(level=-1,drop=True))\n",
    "    \n",
    "    df_new2 = (df_new\n",
    "            .groupby(level=[0,1])\n",
    "            .apply(lambda x: time_shift(x, feature, 2))\n",
    "            .reset_index(level=-1,drop=True))\n",
    "    \n",
    "    df_new = pd.merge(df_new1.reset_index(),\n",
    "                      df_new2.reset_index().drop([feature], axis=1),\n",
    "                      on=df_new1.index.names + ['date']).set_index(df_new1.index.names)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:20:16.357314",
     "start_time": "2016-07-30T16:19:45.841774"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Shift the one and two week prior data\n",
    "\n",
    "max_temp = create_weather_feature(weather_combined, 'Max Temperature').set_index('date',append=True)\n",
    "mean_temp = create_weather_feature(weather_combined, 'Mean Temperature').set_index('date',append=True)\n",
    "min_temp = create_weather_feature(weather_combined, 'Min Temperature').set_index('date',append=True)\n",
    "dew_point = create_weather_feature(weather_combined, 'Dew Point').set_index('date',append=True)\n",
    "precipitation = create_weather_feature(weather_combined, 'Precipitation').set_index('date',append=True)\n",
    "wind = create_weather_feature(weather_combined, 'Wind').set_index('date',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:20:16.368059",
     "start_time": "2016-07-30T16:20:16.360559"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.shape for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:20:16.399510",
     "start_time": "2016-07-30T16:20:16.370939"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.isnull().sum().max() for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "Impute missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:20:26.965501",
     "start_time": "2016-07-30T16:20:26.941323"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "max_temp = max_temp.interpolate(method='linear', limit_direction='both')\n",
    "mean_temp = mean_temp.interpolate(method='linear', limit_direction='both')\n",
    "min_temp = min_temp.interpolate(method='linear', limit_direction='both')\n",
    "dew_point = dew_point.interpolate(method='linear', limit_direction='both')\n",
    "precipitation = precipitation.interpolate(method='linear', limit_direction='both')\n",
    "wind = wind.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:20:38.357231",
     "start_time": "2016-07-30T16:20:38.348713"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.shape for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:20:44.493146",
     "start_time": "2016-07-30T16:20:44.471351"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.isnull().sum().max() for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "Add location key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:48:37.888502",
     "start_time": "2016-07-31T16:48:37.763081"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "airport = pd.read_pickle('../pkl/04_merged_latitude_longitude_airport_checkpoint.pkl')\n",
    "airport.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:22:00.837434",
     "start_time": "2016-07-30T16:22:00.648957"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "max_temp = pd.merge(max_temp.reset_index(),\n",
    "         airport[['ICAO','IATA','location']],\n",
    "         on=['ICAO','IATA'],\n",
    "         how='left')#.drop_duplicates(subset=['location'])\n",
    "\n",
    "mean_temp = pd.merge(mean_temp.reset_index(),\n",
    "         airport[['ICAO','IATA','location']],\n",
    "         on=['ICAO','IATA'],\n",
    "         how='left')\n",
    "\n",
    "\n",
    "min_temp = pd.merge(min_temp.reset_index(),\n",
    "         airport[['ICAO','IATA','location']],\n",
    "         on=['ICAO','IATA'],\n",
    "         how='left')\n",
    "\n",
    "\n",
    "dew_point = pd.merge(dew_point.reset_index(),\n",
    "         airport[['ICAO','IATA','location']],\n",
    "         on=['ICAO','IATA'],\n",
    "         how='left')\n",
    "\n",
    "precipitation = pd.merge(precipitation.reset_index(),\n",
    "         airport[['ICAO','IATA','location']],\n",
    "         on=['ICAO','IATA'],\n",
    "         how='left')\n",
    "\n",
    "wind = pd.merge(wind.reset_index(),\n",
    "         airport[['ICAO','IATA','location']],\n",
    "         on=['ICAO','IATA'],\n",
    "         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:22:21.604481",
     "start_time": "2016-07-30T16:22:21.596470"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.shape for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:22:29.837729",
     "start_time": "2016-07-30T16:22:29.586045"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.isnull().sum().max() for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:22:40.012549",
     "start_time": "2016-07-30T16:22:39.810247"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "max_temp = max_temp.drop(['ICAO','IATA'], axis=1).drop_duplicates(subset=['location','date'])\n",
    "max_temp.columns = [x.lower().replace(' ', '_').replace('erature','') for x in max_temp.columns]\n",
    "\n",
    "mean_temp = mean_temp.drop(['ICAO','IATA'], axis=1).drop_duplicates(subset=['location','date'])\n",
    "mean_temp.columns = [x.lower().replace(' ', '_').replace('erature','') for x in mean_temp.columns]\n",
    "\n",
    "min_temp = min_temp.drop(['ICAO','IATA'], axis=1).drop_duplicates(subset=['location','date'])\n",
    "min_temp.columns = [x.lower().replace(' ', '_').replace('erature','') for x in min_temp.columns]\n",
    "\n",
    "dew_point = dew_point.drop(['ICAO','IATA'], axis=1).drop_duplicates(subset=['location','date'])\n",
    "dew_point.columns = [x.lower().replace(' ', '_').replace('erature','') for x in dew_point.columns]\n",
    "\n",
    "precipitation = precipitation.drop(['ICAO','IATA'], axis=1).drop_duplicates(subset=['location','date'])\n",
    "precipitation.columns = [x.lower().replace(' ', '_').replace('erature','') for x in precipitation.columns]\n",
    "\n",
    "wind = wind.drop(['ICAO','IATA'], axis=1).drop_duplicates(subset=['location','date'])\n",
    "wind.columns = [x.lower().replace(' ', '_').replace('erature','') for x in wind.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:22:59.807350",
     "start_time": "2016-07-30T16:22:59.797925"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.shape for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:23:07.343254",
     "start_time": "2016-07-30T16:23:07.226848"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "[x.isnull().sum().max() for x in max_temp, mean_temp, min_temp, dew_point, precipitation, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:25:17.884724",
     "start_time": "2016-07-30T16:25:17.595488"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "print max_temp.shape\n",
    "\n",
    "weather_final = pd.merge(max_temp, mean_temp, on=['date','location'], how='inner')\n",
    "weather_final = pd.merge(weather_final, min_temp, on=['date','location'], how='inner')\n",
    "weather_final = pd.merge(weather_final, dew_point, on=['date','location'], how='inner')\n",
    "weather_final = pd.merge(weather_final, precipitation, on=['date','location'], how='inner')\n",
    "weather_final = pd.merge(weather_final, wind, on=['date','location'], how='inner')\n",
    "\n",
    "print weather_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:25:26.817517",
     "start_time": "2016-07-30T16:25:26.731384"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "weather_final.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:25:58.044178",
     "start_time": "2016-07-30T16:25:58.016395"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "weather_final.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T16:26:07.250451",
     "start_time": "2016-07-30T16:26:07.232171"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T17:45:18.769908",
     "start_time": "2016-07-30T17:11:47.096969"
    },
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "save_it(weather_final, '04_weekly_weather')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
